{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e3139-c52f-45d2-9a3b-6d9c5b0ff441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression code\n",
    "# Load data\n",
    "final_data <- read.csv(\"data.csv\")\n",
    "dim_data <- read.csv(\"dim_data.csv\")\n",
    "\n",
    "# #################################################### Linear Regression Plot ####################################################\n",
    "# Standardize features first\n",
    "features <- c( \"id\", \"BMI\", \"HR\", \"SBP\", \"DBP\", \"hba1c\", \"cr\", \"hdl\", \"ldl\", \"tg\", \"alt\")\n",
    "feature_table <- final_data[features]\n",
    "hosp <- feature_table$hosp\n",
    "id <- feature_table$id\n",
    "feature_table <- feature_table[,-c(1)]  # Remove 'hosp' and 'id' columns for analysis\n",
    "\n",
    "#rank_matrix <- apply(feature_table, 1, rank)  # Rank each feature row-wise\n",
    "rank_matrix <- as.matrix(rank_matrix)\n",
    "\n",
    "# Residualize data\n",
    "for (i in 1:nrow(rank_matrix)){\n",
    "  model <- lm(rank_matrix[i,] ~ final_data$GENDER + final_data$age)\n",
    "  rank_matrix[i,] <- model$residuals  # Replace row with residuals\n",
    "}\n",
    "\n",
    "# Combine residualized data with IDs\n",
    "processed_data <- cbind(hosp, id, t(rank_matrix))\n",
    "\n",
    "# Merge residualized data with dimension coordinates\n",
    "regression_data <- merge(processed_data, dim_data, by = c(\"id\"))\n",
    "\n",
    "######## Batch linear regression for multiple variables, no modifications needed\n",
    "# Load necessary libraries\n",
    "library(tidyverse)\n",
    "library(rms)\n",
    "\n",
    "# Define regression function\n",
    "regression2 <- function(x) {\n",
    "  # Fit linear model adjusting for hk_test_dim1 and hk_test_dim2\n",
    "  model <- lm(x ~ hk_test_dim1 + hk_test_dim2, data = regression_data)\n",
    "  \n",
    "  # Extract model coefficients and confidence intervals\n",
    "  coefficients <- coef(model)\n",
    "  conf_intervals <- confint(model)\n",
    "  \n",
    "  # Convert to data frame\n",
    "  coefficients_df <- as.data.frame(coefficients)\n",
    "  coefficients_df$CI_low <- conf_intervals[, 1]\n",
    "  coefficients_df$CI_high <- conf_intervals[, 2]\n",
    "  \n",
    "  return(coefficients_df)\n",
    "}\n",
    "\n",
    "# Apply regression to each variable and organize results\n",
    "result <- map(regression_data[, c(3:12)], regression2) %>%\n",
    "  do.call(rbind, .) %>%\n",
    "  as.data.frame() %>%\n",
    "  rownames_to_column(\"trait\")\n",
    "\n",
    "# Remove rows with Intercept term\n",
    "result <- result %>% filter(!str_detect(trait, \"Intercept\"))\n",
    "\n",
    "# Assign variable names and Dimension labels\n",
    "variable_names <- c(\"BMI\", \"HR\", \"SBP\", \"DBP\", \"HbA1c\", \"CREAT\", \"HDL-C\", \"LDL-C\", \"TRIG\", \"ALT\")\n",
    "result <- result %>%\n",
    "  mutate(\n",
    "    name = rep(variable_names, each = 2),\n",
    "    trait = rep(c(\"Dimension1\", \"Dimension2\"), times = length(variable_names))\n",
    "  ) %>%\n",
    "  rename(beta = coefficients)\n",
    "\n",
    "# Rearrange columns for final output table\n",
    "final_table <- result %>% select(name, trait, beta, CI_low, CI_high)\n",
    "\n",
    "# Display and save final results table\n",
    "print(final_table)\n",
    "write.csv(final_table, \"linear regression.csv\")\n",
    "\n",
    "# ################# Plotting Linear Regression, no modifications needed #################\n",
    "library(ggplot2)\n",
    "final_table <- read.csv(\"linear regression.csv\")\n",
    "\n",
    "final_plot <- ggplot(final_table, aes(x = beta, y = reorder(name, beta), color = trait)) +\n",
    "  geom_point(size = 3) +  # Plot regression coefficients\n",
    "  geom_errorbarh(aes(xmin = CI_low, xmax = CI_high), height = 0.35) +  # Plot confidence intervals\n",
    "  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"black\") +  # Add zero line\n",
    "  labs(title = \"Regression Coefficients with 95% CI\",\n",
    "       x = \"Regression Coefficient\",\n",
    "       y = \"Model\",\n",
    "       color = \"Dimension\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Display plot\n",
    "print(final_plot)\n",
    "\n",
    "# Save plot\n",
    "ggsave(\"figure_linear_regression.png\", plot = final_plot, width = 8, height = 6, dpi = 300)\n",
    "\n",
    "    term = rep(c(\"Dimension1\", \"Dimension2\"), times = length(variable_names))\n",
    "  )\n",
    "write.csv(final_results, \"cox regression.csv\")\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46f3fe-b784-4e82-8d27-127bc89a0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def compareABunchOfDifferentModelsAccuracy(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Compare multiple classifiers using 10-fold cross-validation\n",
    "    \"\"\"\n",
    "    print('\\nCompare Multiple Classifiers: \\n')\n",
    "    print('K-Fold Cross-Validation Accuracy: \\n')\n",
    "\n",
    "    models = {\n",
    "        'LR': LogisticRegression(),\n",
    "        'RF': RandomForestClassifier(),\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'SVM': SVC(),\n",
    "        'LSVM': LinearSVC(),\n",
    "        'GNB': GaussianNB(),\n",
    "        'DTC': DecisionTreeClassifier(),\n",
    "        'GBC': GradientBoostingClassifier(),\n",
    "        'LASSO (L1)': LogisticRegressionCV(\n",
    "            Cs=10, cv=10, penalty='l1', solver='saga', max_iter=10000, scoring='accuracy', refit=True\n",
    "        ),\n",
    "        'Elastic Net': LogisticRegressionCV(\n",
    "            Cs=10, cv=10, penalty='elasticnet', solver='saga',\n",
    "            l1_ratios=[.1, .5, .9], max_iter=10000,\n",
    "            scoring='accuracy', refit=True\n",
    "        )\n",
    "    }\n",
    "\n",
    "    names = []\n",
    "    resultsAccuracy = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        accuracy_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "        resultsAccuracy.append(accuracy_results)\n",
    "        names.append(name)\n",
    "        print(f\"{name}: {accuracy_results.mean():.4f} (+/- {accuracy_results.std():.4f})\")\n",
    "\n",
    "    # 可视化 boxplot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=resultsAccuracy, palette='viridis')\n",
    "    plt.xticks(ticks=range(len(names)), labels=names, rotation=45)\n",
    "    plt.ylabel('Accuracy Score')\n",
    "    plt.title('Comparison of Classifier Accuracy (10-fold CV)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def defineModels():\n",
    "    print('LR = LogisticRegression')\n",
    "    print('RF = RandomForestClassifier')\n",
    "    print('KNN = KNeighborsClassifier')\n",
    "    print('SVM = Support Vector Machine SVC')\n",
    "    print('LSVM = LinearSVC')\n",
    "    print('GNB = GaussianNB')\n",
    "    print('DTC = DecisionTreeClassifier')\n",
    "    print('GBC = GradientBoostingClassifier')\n",
    "    print('LASSO (L1) = LogisticRegressionCV with L1')\n",
    "    print('Elastic Net = LogisticRegressionCV with ElasticNet\\n\\n')\n",
    "\n",
    "data = read_csv('....csv')\n",
    "X = data.iloc[:, 1:]  # except diabetes= X\n",
    "y = data.iloc[:, 0]   # diabetes=y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train3 = pd.DataFrame(X_train)\n",
    "print(y_train.dtype)  \n",
    "print(y_train.unique())  \n",
    "\n",
    "compareABunchOfDifferentModelsAccuracy(X_train, y_train)\n",
    "defineModels()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "save_path = r\".tiff\"\n",
    "plt.savefig(save_path, dpi=300, format='tiff', bbox_inches='tight')\n",
    "\n",
    "#\n",
    "plt.show()\n",
    "\n",
    "print(f\"figure saved: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bddeb4c-4fee-4e1d-b5f9-5d00c1f8c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUPFig4\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# \n",
    "models = {\n",
    "    'LR': LogisticRegression(max_iter=1000),\n",
    "    'RF': RandomForestClassifier(n_estimators=100),\n",
    "    'SVM': SVC(kernel='rbf', probability=True),\n",
    "    'LinearSVM': LinearSVC(max_iter=10000),\n",
    "    'GBC': GradientBoostingClassifier(),\n",
    "    'GNB': GaussianNB(),\n",
    "    'DTC': DecisionTreeClassifier(),\n",
    "    'LASSO': Lasso(alpha=0.01, max_iter=10000),\n",
    "    'ElasticNet': ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=10000)\n",
    "}\n",
    "\n",
    "print(\"\\nModel Comparison: ROC AUC and PR AUC\\n\")\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    pr_auc = average_precision_score(y_test, y_proba)\n",
    "    print(f\"{name:20s} | ROC AUC: {roc_auc:.3f} | PR AUC: {pr_auc:.3f}\")\n",
    "    \n",
    "plt.figure(figsize=(12, 5))\n",
    "# ROC Curve\n",
    "plt.subplot(1, 2, 1)\n",
    "for name, model in models.items():\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc_score:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for All Models')\n",
    "plt.legend()\n",
    "\n",
    "# PR Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "for name, model in models.items():\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    pr_auc = average_precision_score(y_test, y_proba)\n",
    "    plt.plot(recall, precision, label=f\"{name} (AUC={pr_auc:.2f})\")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve for All Models')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams.update({'font.family': 'Arial', 'font.size': 12})\n",
    "plt.savefig(\"model_comparison_auc.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51de558-bd63-4a1e-a605-b879a13d27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare GBC and RF \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: defination\n",
    "feature_sets = {\n",
    "    \"Top 5\": [\"HDL-C\", \"TG\", \"SBP\", \"ALT\", \"HbA1c\"],\n",
    "    \"Top 6\": [\"HDL-C\", \"TG\", \"SBP\", \"ALT\", \"HbA1c\", \"LDL-C\"],\n",
    "    \"Top 7\": [\"HDL-C\", \"TG\", \"SBP\", \"ALT\", \"HbA1c\", \"LDL-C\", \"HR\"],\n",
    "    \"Top 8\": [\"HDL-C\", \"TG\", \"SBP\", \"ALT\", \"HbA1c\", \"LDL-C\", \"HR\", \"BMI\"],\n",
    "    \"Top 9\": [\"HDL-C\", \"TG\", \"SBP\", \"ALT\", \"HbA1c\", \"LDL-C\", \"HR\", \"BMI\", \"DBP\"],\n",
    "    \"Top 10\": [\"HDL-C\", \"TG\", \"SBP\", \"ALT\", \"HbA1c\", \"LDL-C\", \"HR\", \"BMI\", \"DBP\", \"CREAT\"]\n",
    "}\n",
    "\n",
    "# Step 2: read data\n",
    "data = pd.read_csv('/ahsl.csv')\n",
    "\n",
    "# Step 3: \n",
    "models = {\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for set_name, features in feature_sets.items():\n",
    "        X = data[features]\n",
    "        y = data['diabetes']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        roc = roc_auc_score(y_test, y_proba)\n",
    "        pr = average_precision_score(y_test, y_proba)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Features\": set_name,\n",
    "            \"ROC AUC\": roc,\n",
    "            \"PR AUC\": pr,\n",
    "            \"F1 Score\": f1\n",
    "        })\n",
    "\n",
    "# Step 4: DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "#Visualize SUPfig4\n",
    "import seaborn as sns\n",
    "\n",
    "metrics = [\"ROC AUC\", \"PR AUC\", \"F1 Score\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=results_df, x=\"Features\", y=metric, hue=\"Model\", marker=\"o\")\n",
    "    plt.title(f\"{metric} vs Number of Features\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374745c4-a5ab-412f-a5a4-91b7b51de934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Fig6F sankey\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# read data\n",
    "data = pd.read_excel('....xlsx')\n",
    "\n",
    "nodes_ordered = list(pd.unique(data['source'].tolist() + data['target'].tolist()))\n",
    "\n",
    "node_indices = {node: i for i, node in enumerate(nodes_ordered)}\n",
    "\n",
    "data['source'] = data['source'].map(node_indices)\n",
    "data['target'] = data['target'].map(node_indices)\n",
    "\n",
    "node_labels = nodes_ordered\n",
    "\n",
    "sankey_fig = go.Figure(go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=node_labels,\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=data['source'],  # \n",
    "        target=data['target'],  # \n",
    "        value=data['value'],    # \n",
    "    )\n",
    "))\n",
    "\n",
    "sankey_fig.update_layout(title_text=\"Energy\", title_x=0.5)\n",
    "\n",
    "sankey_fig.write_html(\"sankey_plot_0801001.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d23a14-3ac8-4725-93f2-05e4a0e4ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####SUPFig13 metabolic change\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pd.read_excel('...0922.xlsx')\n",
    "\n",
    "# clean NaN\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# delta \n",
    "delta_columns = ['delta_bmi', 'delta_sbp', 'delta_dbp', 'delta_hr', 'delta_hba1c',\n",
    "                 'delta_cr', 'delta_tcho', 'delta_hdl', 'delta_ldl', 'delta_alt', 'delta_ast', 'delta_glu']\n",
    "\n",
    "# set 3x4 \n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, delta_var in enumerate(delta_columns):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    heatmap_data = df.pivot(index=\"Source\", columns=\"Target\", values=delta_var)\n",
    "    sns.heatmap(heatmap_data, annot=True, cmap=\"coolwarm\", linewidths=0.5, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'{delta_var} change')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07262326-da47-477e-9ba6-942741f62478",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SUPFig14\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# dataframe\n",
    "groups = ['Group1','Group2','Group3','Group4','Group5','Group6']\n",
    "\n",
    "# complications\n",
    "complications = ['MI', 'Stroke', 'I stroke', 'IH stroke', 'HF', 'DR', 'CKD', 'ESRD', 'PD', 'MASLD', 'Cirrhosis']\n",
    "\n",
    "# contain Group1~6\n",
    "data_raw = {\n",
    "    ('Group1','Group1'): [6,27,24,1,13,16,17,5,5,53,6],\n",
    "    ('Group1','Group2'): [1,4,4,1,4,3,0,0,0,10,1],\n",
    "    ('Group1','Group3'): [1,0,0,0,1,2,0,0,1,2,0],\n",
    "    ('Group1','Group4'): [0,0,0,0,0,0,0,0,0,0,0],\n",
    "    ('Group1','Group5'): [0,1,1,0,1,0,0,0,0,0,0],\n",
    "    ('Group1','Group6'): [0,5,5,1,2,7,3,1,1,16,2],\n",
    "    \n",
    "    ('Group2','Group1'): [1,4,4,1,2,5,0,0,5,12,1],\n",
    "    ('Group2','Group2'): [3,7,4,1,8,6,4,5,3,20,1],\n",
    "    ('Group2','Group3'): [0,0,0,0,1,0,0,0,0,1,0],\n",
    "    ('Group2','Group4'): [0,0,0,0,0,0,0,0,0,1,1],\n",
    "    ('Group2','Group5'): [0,0,0,0,0,0,1,1,0,0,0],\n",
    "    ('Group2','Group6'): [0,4,4,0,1,3,2,0,1,0,2],\n",
    "    \n",
    "    ('Group3','Group1'): [0,3,2,0,1,1,0,0,0,1,0],\n",
    "    ('Group3','Group2'): [0,0,0,0,1,0,0,0,0,1,0],\n",
    "    ('Group3','Group3'): [1,3,2,1,2,2,4,1,2,8,1],\n",
    "    ('Group3','Group4'): [0,0,0,2,0,0,1,0,0,0,0],\n",
    "    ('Group3','Group5'): [0,0,0,0,0,0,0,0,0,0,0],\n",
    "    ('Group3','Group6'): [0,0,0,0,0,0,0,0,0,0,0],\n",
    "    \n",
    "    ('Group4','Group1'): [0,0,0,0,0,0,0,0,0,0,0],\n",
    "    ('Group4','Group2'): [0,0,0,0,0,0,0,0,0,0,0],\n",
    "    ('Group4','Group3'): [0,1,1,0,0,0,0,0,0,0,0],\n",
    "    ('Group4','Group4'): [0,0,0,0,1,1,1,0,1,2,1],\n",
    "    ('Group4','Group5'): [1,2,2,0,2,1,1,0,0,1,1],\n",
    "    ('Group4','Group6'): [0,0,0,0,0,0,0,0,0,0,0],\n",
    "    \n",
    "    ('Group5','Group1'): [0,1,0,0,1,2,1,0,0,2,0],\n",
    "    ('Group5','Group2'): [0,1,1,0,0,1,0,0,1,1,0],\n",
    "    ('Group5','Group3'): [0,0,0,0,0,0,0,0,0,0,0],\n",
    "    ('Group5','Group4'): [1,1,1,0,1,1,1,0,1,4,3],\n",
    "    ('Group5','Group5'): [0,14,10,1,7,10,7,4,0,53,1],\n",
    "    ('Group5','Group6'): [2,10,9,0,4,7,4,2,3,24,2],\n",
    "    \n",
    "    ('Group6','Group1'): [0,8,8,0,6,5,7,3,0,16,2],\n",
    "    ('Group6','Group2'): [0,2,2,0,1,1,1,1,1,1,0],\n",
    "    ('Group6','Group3'): [0,0,0,0,0,1,0,0,0,1,1],\n",
    "    ('Group6','Group4'): [0,0,0,0,0,1,0,0,0,1,1],\n",
    "    ('Group6','Group5'): [0,6,6,1,1,4,1,1,1,12,0],\n",
    "    ('Group6','Group6'): [4,29,27,4,14,25,12,3,4,76,4],\n",
    "}\n",
    "\n",
    "# DataFrame\n",
    "index = pd.MultiIndex.from_tuples(data_raw.keys(), names=['From', 'To'])\n",
    "df = pd.DataFrame(list(data_raw.values()), index=index, columns=complications)\n",
    "df = df.loc[(slice('Group1','Group6'), slice('Group1','Group6')), :]\n",
    "\n",
    "# heatmap\n",
    "plt.figure(figsize=(18, 25))\n",
    "for i, comp in enumerate(complications):\n",
    "    plt.subplot(6, 2, i+1)\n",
    "    pivot_table = df[comp].unstack(level='To')\n",
    "    sns.heatmap(pivot_table, annot=True, fmt='d', cmap='YlGnBu', cbar_kws={'label': 'Events'})\n",
    "    plt.title(f'Events of {comp} by Group Transition')\n",
    "    plt.xlabel('To Group')\n",
    "    plt.ylabel('From Group')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf1c97-0505-4f56-a72d-9fb65abed6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chinese mapping function\n",
    "#################################################################### First Part: Calculate Coordinates and Generate Feature Plots ##########################################################\n",
    "setwd(\"china tree mapping function\")\n",
    "\n",
    "# Load necessary data\n",
    "load(\"china_dim.RData\")\n",
    "load(\"Chinese_gam_x.rds\")\n",
    "load(\"Chinese_gam_y.rds\")\n",
    "\n",
    "##################################### The function definition below does not need modification ######################################################\n",
    "ddrtree_map <- function(data) {\n",
    "  library(mgcv)\n",
    "  library(ggplot2)\n",
    "  \n",
    "  # Prepare the data\n",
    "  names(data)[1] <- 'GENDER'\n",
    "  names(data)[2] <- 'age'\n",
    "  names(data)[3] <- 'hdl'\n",
    "  names(data)[4] <- 'ldl'\n",
    "  names(data)[5] <- 'tg'\n",
    "  names(data)[6] <- 'hba1c'\n",
    "  names(data)[7] <- 'BMI'\n",
    "  names(data)[8] <- 'SBP'\n",
    "  names(data)[9] <- 'DBP'\n",
    "  names(data)[10] <- 'alt'\n",
    "  names(data)[11] <- 'cr'\n",
    "  names(data)[12] <- 'HR'\n",
    "  \n",
    "  print(names(data))\n",
    "  \n",
    "  # Data type conversion\n",
    "  data[, c(2:12)] <- apply(data[, c(2:12)], 2, function(x) as.numeric(as.character(x)))\n",
    "  data$GENDER <- factor(data$GENDER, levels = c('1', '2'))\n",
    "  \n",
    "  # Get the position prediction\n",
    "  dim1 <- predict.gam(Chinese_gam_x, newdata = data)\n",
    "  dim2 <- predict.gam(Chinese_gam_y, newdata = data)\n",
    "  \n",
    "  # Initialize new columns\n",
    "  predict_data <- as.data.frame(cbind(dim1, dim2))\n",
    "  predict_data$hk_test_dim1 <- NA\n",
    "  predict_data$hk_test_dim2 <- NA\n",
    "  \n",
    "  # Reposition prediction points based on the Euclidean distance\n",
    "  for (i in 1:nrow(predict_data)) {\n",
    "    distance <- ((china_dim$data_dim_1 - predict_data$dim1[i])^2 + (china_dim$data_dim_2 - predict_data$dim2[i])^2)^0.5\n",
    "    j <- which.min(distance)\n",
    "    predict_data$hk_test_dim1[i] <- china_dim$data_dim_1[j]\n",
    "    predict_data$hk_test_dim2[i] <- china_dim$data_dim_2[j]\n",
    "  }\n",
    "  \n",
    "  # Check structure of predict_data\n",
    "  print(head(predict_data))\n",
    "  \n",
    "  new_predict_data <- as.data.frame(cbind(predict_data, data))\n",
    "  \n",
    "  # Define indicators and color settings\n",
    "  indicators <- c(\"SBP\",\"DBP\",\"hdl\",\"ldl\",\"BMI\",\"tg\",\"cr\",\"alt\",\"hba1c\",\"HR\")  # Indicator column names\n",
    "  color_settings <- list(\n",
    "    SBP = list(color_title = \"SBP\", title = \"SBP (mm of Hg)\", limits = c(80, 200), breaks = c(100, 120, 140, 160, 180), labels = c(\"100\", \"120\", \"140\", \"160\", \"180\"), low = \"#00FFFF\", high = \"red\"),\n",
    "    DBP = list(color_title = \"DBP\", title = \"DBP (mm of Hg)\", limits = c(40, 140), breaks = c(60, 80, 100, 120), labels = c(\"60\", \"80\", \"100\", \"120\"), low = \"#00FFFF\", high = \"red\"),\n",
    "    hdl = list(color_title = \"HDL-C\", title = \"HDL-C (mmol/L)\", limits = c(0, 2), breaks = c(0.5, 1, 1.5), labels = c(\"0.5\", \"1\", \"1.5\"), low = \"#00FFFF\", high = \"red\"),\n",
    "    ldl = list(color_title = \"LDL-C\", title = \"LDL-C (mmol/L)\", limits = c(0, 5), breaks = c(2, 4), labels = c(\"2\", \"4\"), low = \"#00FFFF\", high = \"red\"),\n",
    "    BMI = list(color_title = \"BMI\", title = \"BMI (Kg/m2)\", limits = c(20, 30), breaks = c(22, 24, 26, 28), labels = c(\"22\", \"24\", \"26\", \"28\"), low = \"#00FFFF\", high = \"red\"),\n",
    "    tg = list(color_title = \"TRIG\", title = \"Triglycerides (mmol/L)\", limits = c(0, 5), breaks = c(2, 4), labels = c(\"2\", \"4\"), low = \"#00FFFF\", high = \"red\"),\n",
    "    cr = list(color_title = \"CREAT\", title = \"Creatinine (umol/L)\", limits = c(50, 100), breaks = c(60, 70, 80, 90), labels = c(\"60\", \"70\", \"80\", \"90\"), low = \"#00FFFF\", high = \"red\"),\n",
    "    alt = list(color_title = \"ALT\", title = \"ALT (IU/L)\", limits = c(0, 75), breaks = c(15, 30, 45, 60), labels = c(\"15\", \"30\", \"45\", \"60\"), low = \"#00FFFF\", high = \"red\"),\n",
    "    hba1c = list(color_title = \"HbA1c\", title = \"HbA1c (%)\", limits = c(5, 12), breaks = c(6, 8, 10), labels = c(\"6\", \"8\", \"10\"), low = \"#00FFFF\", high = \"red\"),\n",
    "    HR = list(color_title = \"HR\", title = \"HR (bpm)\", limits = c(45, 135), breaks = c(60, 75, 90, 105, 120), labels = c(\"60\", \"75\", \"90\", \"105\", \"120\"), low = \"#00FFFF\", high = \"red\")\n",
    "  )\n",
    "  \n",
    "  create_plot <- function(indicator) {\n",
    "    settings <- color_settings[[indicator]]\n",
    "    \n",
    "    # Base layer\n",
    "    k <- ggplot(china_dim, aes(x = data_dim_1, y = data_dim_2)) +\n",
    "      geom_point(color = 'grey') +  # Original data points in grey\n",
    "      xlab('Dimension 1') +\n",
    "      ylab('Dimension 2') +\n",
    "      theme_minimal() +\n",
    "      labs(title = settings$title) +\n",
    "      theme(plot.title = element_text(size = 22, face = \"bold\"))\n",
    "    \n",
    "    # Add new layer on top of prediction points\n",
    "    final_plot <- k +\n",
    "      geom_point(data = new_predict_data, aes_string(x = 'hk_test_dim1', y = 'hk_test_dim2', color = indicator), size = 2) +\n",
    "      scale_color_gradient(\n",
    "        limits = settings$limits,\n",
    "        breaks = settings$breaks,\n",
    "        labels = settings$labels,\n",
    "        low = settings$low,\n",
    "        high = settings$high,\n",
    "        oob = scales::squish\n",
    "      ) +\n",
    "      labs(color = settings$color_title) +\n",
    "      theme(legend.text = element_text(size = 15),\n",
    "            legend.title = element_text(size = 16))\n",
    "    \n",
    "    return(final_plot)\n",
    "  }\n",
    "  \n",
    "  # Return the predicted data\n",
    "  return(list(predict_data = predict_data, create_plot = create_plot, indicators = indicators))\n",
    "}\n",
    "\n",
    "###########################################################################\n",
    "# Read data, modify the file path as necessary\n",
    "data <- read.csv(\"sampledata.csv\")\n",
    "\n",
    "data2 <- data[, !names(data) %in% \"id\"] #remove col\"id\"\n",
    "\n",
    "# Call ddrtree_map function to get predictions, no modifications needed\n",
    "result <- ddrtree_map(data2)\n",
    "\n",
    "# Get predicted data, no modifications needed\n",
    "predicted_data <- result$predict_data\n",
    "new_data <- cbind(data, predicted_data)\n",
    "\n",
    "# Save the data, modify the file path as necessary\n",
    "write.csv(new_data, \"new_data.csv\")\n",
    "\n",
    "# Generate and save the plots for each indicator, modify the file path as necessary\n",
    "for (indicator in result$indicators) {\n",
    "  plot <- result$create_plot(indicator)\n",
    "  ggsave(paste0(\"/ahsl/\", indicator, \"_plot.png\"), plot, width = 8, height = 6)\n",
    "}\n",
    "\n",
    "#################################################################### Second Part: Competing Risk Model to Calculate Complication Risk Probability ########################\n",
    "outcome_data <- read.csv(\"sampleoutcome.csv\")  # Load the dataset containing outcome data\n",
    "\n",
    "final_data <- merge(outcome_data, new_data, by = \"id\")  # Merge with the dataset containing the calculated coordinates, ensuring accurate matching\n",
    "\n",
    "# Load necessary packages\n",
    "library(cmprsk)\n",
    "library(rms)\n",
    "\n",
    "################################ General Function: Calculate survival time and cumulative incidence probability, no need to modify #####################\n",
    "calculate_survival_and_prediction <- function(final_data, outcome_name, outcome_date_col, risk_col, crr_model_covariates) {\n",
    "  # Calculate survival time\n",
    "  survival_time_col <- paste0(\"survival_time_\", outcome_name)\n",
    "  final_data[[survival_time_col]] <- as.numeric((as.Date(final_data[[outcome_date_col]]) - as.Date(final_data$visit_start_date)) / 365)\n",
    "  \n",
    "  # Calculate risk variable\n",
    "  risk_col_name <- paste0(\"risk_\", outcome_name)\n",
    "  final_data[[risk_col_name]] <- ifelse(final_data[[risk_col]] == 0 & final_data$dead == 0, 0, \n",
    "                                        ifelse(final_data[[risk_col]] == 1 & final_data$dead == 0, 1, 2))\n",
    "  \n",
    "  # Check for missing values in survival time and status, and filter data\n",
    "  valid_data <- final_data[!is.na(final_data[[survival_time_col]]) & !is.na(final_data[[risk_col_name]]), ]\n",
    "  \n",
    "  # Create Cox regression model (crr)\n",
    "  crr_model <- crr(ftime = valid_data[[survival_time_col]],\n",
    "                   fstatus = valid_data[[risk_col_name]],\n",
    "                   cov1 = as.matrix(valid_data[, crr_model_covariates]),\n",
    "                   cencode = 0,\n",
    "                   failcode = 1)\n",
    "  \n",
    "  # Output model summary\n",
    "  print(summary(crr_model))\n",
    "  \n",
    "  # Get cumulative incidence probabilities from the fitted model\n",
    "  predictions <- predict(crr_model, cov1 = as.matrix(valid_data[, crr_model_covariates]))\n",
    "  \n",
    "  # Get cumulative incidence probability at the last time point\n",
    "  last_time_point_predictions <- predictions[, ncol(predictions)]\n",
    "  \n",
    "  # Format prediction results\n",
    "  predictions_formatted <- format(last_time_point_predictions, digits = 4)\n",
    "  \n",
    "  # Create result column and add prediction results to the full dataset\n",
    "  probability_col_name <- paste0(outcome_name, \"_probability\")\n",
    "  final_data[[probability_col_name]] <- NA  # Initialize the result column\n",
    "  final_data[[probability_col_name]][!is.na(final_data[[survival_time_col]]) & !is.na(final_data[[risk_col_name]])] <- predictions_formatted\n",
    "  \n",
    "  return(final_data)\n",
    "}\n",
    "\n",
    "################## Define outcome names, corresponding date columns, and risk columns (modify based on actual data) ################\n",
    "outcome_list <- list(\n",
    "  list(\"name\" = \"MAFLD\", \"date_col\" = \"MAFLD_date\", \"risk_col\" = \"MAFLD\"),\n",
    "  list(\"name\" = \"Cirrhosis\", \"date_col\" = \"Cirrhosis_date\", \"risk_col\" = \"Cirrhosis\"),\n",
    "  list(\"name\" = \"MI\", \"date_col\" = \"MI_date\", \"risk_col\" = \"MI\"),\n",
    "  list(\"name\" = \"Stroke\", \"date_col\" = \"Stroke_date\", \"risk_col\" = \"Stroke\"),\n",
    "  list(\"name\" = \"Istroke\", \"date_col\" = \"Istroke_date\", \"risk_col\" = \"Istroke\"),\n",
    "  list(\"name\" = \"IHstroke\", \"date_col\" = \"IHstroke_date\", \"risk_col\" = \"IHstroke\"),\n",
    "  list(\"name\" = \"HF\", \"date_col\" = \"HF_date\", \"risk_col\" = \"HF\"),\n",
    "  list(\"name\" = \"HFrEF\", \"date_col\" = \"HFrEF_date\", \"risk_col\" = \"HFrEF\"),\n",
    "  list(\"name\" = \"HFpEF\", \"date_col\" = \"HFpEF_date\", \"risk_col\" = \"HFpEF\"),\n",
    "  list(\"name\" = \"CKD\", \"date_col\" = \"CKD_date\", \"risk_col\" = \"CKD\"),\n",
    "  list(\"name\" = \"ESRD\", \"date_col\" = \"ESRD_date\", \"risk_col\" = \"ESRD\"),\n",
    "  list(\"name\" = \"DR\", \"date_col\" = \"DR_date\", \"risk_col\" = \"DR\")\n",
    ")\n",
    "\n",
    "# No modification needed\n",
    "crr_model_covariates <- c(\"hk_test_dim1\", \"hk_test_dim2\")\n",
    "\n",
    "# Loop through each outcome to calculate survival time and cumulative incidence probability. No modification needed. #########\n",
    "for (outcome in outcome_list) {\n",
    "  final_data <- calculate_survival_and_prediction(\n",
    "    final_data,\n",
    "    outcome_name = outcome$name,\n",
    "    outcome_date_col = outcome$date_col,\n",
    "    risk_col = outcome$risk_col,\n",
    "    crr_model_covariates = crr_model_covariates\n",
    "  )\n",
    "}\n",
    "\n",
    "# View the final merged dataset\n",
    "colnames(final_data)\n",
    "head(final_data)\n",
    "\n",
    "write.csv(final_data, \"final_data.csv\")\n",
    "\n",
    "####################################################### Third Part: Visualization ###################################################\n",
    "final_data <- read.csv(\"final_data.csv\")  # Load the saved final_data.csv\n",
    "\n",
    "colnames(final_data)\n",
    "library(ggplot2)\n",
    "library(scales)\n",
    "library(purrr)\n",
    "\n",
    "### Modify based on actual data\n",
    "indicators <- c(\"MAFLD_probability\", \"Cirrhosis_probability\", \"MI_probability\", \"Stroke_probability\", \"Istroke_probability\", \"IHstroke_probability\", \"HF_probability\", \"HFrEF_probability\", \"HFpEF_probability\", \"CKD_probability\", \"ESRD_probability\", \"DR_probability\")  # Get indicator column names\n",
    "color_settings <- list(\n",
    "  MAFLD_probability = list(color_title = \"Probability of MAFLD\", title = \"Probability of MAFLD\",  low = \"#00FFFF\", high = \"red\"),\n",
    "  Cirrhosis_probability = list(color_title = \"Probability of Cirrhosis\", title = \"Probability of Cirrhosis\", low = \"#00FFFF\", high = \"red\"),\n",
    "  MI_probability = list(color_title = \"Probability of MI\", title = \"Probability of MI\",  low = \"#00FFFF\", high = \"red\"),\n",
    "  Stroke_probability = list(color_title = \"Probability of Stroke\", title = \"Probability of Stroke\",  low = \"#00FFFF\", high = \"red\"),\n",
    "  Istroke_probability = list(color_title = \"Probability of Istroke\", title = \"Probability of Istroke\", low = \"#00FFFF\", high = \"red\"),\n",
    "  IHstroke_probability = list(color_title = \"Probability of IHstroke\", title = \"Probability of IHstroke\",  low = \"#00FFFF\", high = \"red\"),\n",
    "  HF_probability = list(color_title = \"Probability of HF\", title = \"Probability of HF\",  low = \"#00FFFF\", high = \"red\"),\n",
    "  HFrEF_probability = list(color_title = \"Probability of HFrEF\", title = \"Probability of HFrEF\", low = \"#00FFFF\", high = \"red\"),\n",
    "  HFpEF_probability = list(color_title = \"Probability of HFpEF\", title = \"Probability of HFpEF\", low = \"#00FFFF\", high = \"red\"),\n",
    "  CKD_probability = list(color_title = \"Probability of CKD\", title = \"Probability of CKD\", low = \"#00FFFF\", high = \"red\"),\n",
    "  ESRD_probability = list(color_title = \"Probability of ESRD\", title = \"Probability of ESRD\", low = \"#00FFFF\", high = \"red\"),\n",
    "  DR_probability = list(color_title = \"Probability of DR\", title = \"Probability of DR\",  low = \"#00FFFF\", high = \"red\")\n",
    ")\n",
    "\n",
    "############################### Define function, no need to modify #####################################\n",
    "create_plot <- function(indicator) {\n",
    "  settings <- color_settings[[indicator]]\n",
    "  \n",
    "  # Ensure the indicator column is numeric\n",
    "  final_data[[indicator]] <- as.numeric(final_data[[indicator]])\n",
    "  \n",
    "  # Base plot\n",
    "  k <- ggplot(china_dim, aes(x = data_dim_1, y = data_dim_2)) +\n",
    "    geom_point(color = 'grey') +  # Original data points in grey\n",
    "    xlab('Dimension 1') +\n",
    "    ylab('Dimension 2') +\n",
    "    theme_minimal() +\n",
    "    labs(title = settings$title) +\n",
    "    theme(plot.title = element_text(size = 22, face = \"bold\"))\n",
    "  \n",
    "  # Overlay new layer with prediction points\n",
    "  final_plot <- k +\n",
    "    geom_point(data = final_data, aes(x = hk_test_dim1, y = hk_test_dim2, color = !!sym(indicator)), size = 2) + \n",
    "    scale_color_gradient(\n",
    "      low = settings$low,\n",
    "      high = settings$high\n",
    "    ) +\n",
    "    labs(color = settings$color_title) +\n",
    "    theme(legend.text = element_text(size = 15),\n",
    "          legend.title = element_text(size = 16))\n",
    "  \n",
    "  return(final_plot)\n",
    "}\n",
    "\n",
    "#################################################################### Plotting #########\n",
    "plots <- map(indicators, create_plot)\n",
    "folder_path <- \"/ashl/\"  # Set the path to save the images\n",
    "\n",
    "#########no need to modify #####################################\n",
    "save_plot <- function(plot, indicator) {\n",
    "  file.name <- paste0(\"plot_outcome_\", indicator, \".png\")\n",
    "  file_path <- file.path(folder_path, file.name)\n",
    "  ggsave(filename = file_path, plot = plot, width = 8, height = 6)\n",
    "  cat(\"Plot saved as:\", file_path, \"\\n\")\n",
    "}\n",
    "\n",
    "walk2(plots, indicators, save_plot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
